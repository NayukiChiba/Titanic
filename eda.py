"""
æ¢ç´¢æ€§æ•°æ®åˆ†ææ¨¡å—

åŠŸèƒ½ï¼š
1. è¯»å…¥ä¸æ¦‚è§ˆ(å·²å®Œæˆ):    å½¢çŠ¶ã€å‰å‡ è¡Œ/åå‡ è¡Œã€æ•°æ®ç±»å‹ã€infoã€describe
2. è´¨é‡æ£€æŸ¥(å·²å®Œæˆ):     ç¼ºå¤±å€¼ã€é‡å¤å€¼ã€å¼‚å¸¸å€¼ã€ç¦»ç¾¤ç‚¹
3. å•å˜é‡åˆ†æ(å·²å®Œæˆ):    æ•°å€¼åˆ—åˆ†å¸ƒï¼ˆç›´æ–¹å›¾/ç®±çº¿å›¾ï¼‰ã€ç±»åˆ«åˆ—åˆ†å¸ƒï¼ˆè®¡æ•°å›¾ï¼‰
4. ç›®æ ‡å˜é‡åˆ†æ(å·²å®Œæˆ):   ç›®æ ‡åˆ†å¸ƒã€ç±»åˆ«ä¸å¹³è¡¡æƒ…å†µ
5. ç‰¹å¾ä¸ç›®æ ‡å…³ç³»(å·²å®Œæˆ): ç±»åˆ«-ç›®æ ‡å‡å€¼ã€æ•°å€¼-ç›®æ ‡ç®±çº¿/åˆ†å¸ƒå¯¹æ¯”
6. ç‰¹å¾ä¹‹é—´å…³ç³»(å·²å®Œæˆ):   ç›¸å…³æ€§ã€å…±çº¿æ€§ã€äº¤äº’å…³ç³»
7. åˆæ­¥å¤„ç†å»ºè®®(å·²å®Œæˆ):   ç¼ºå¤±å¡«è¡¥/åˆ é™¤ã€å¼‚å¸¸å¤„ç†ã€ç¼–ç æ–¹å¼ã€ç‰¹å¾å·¥ç¨‹

ä½¿ç”¨æ–¹æ³•ï¼š
    python eda.py
"""

import os
from typing import Any

import numpy as np
import pandas as pd
import seaborn as sns
from matplotlib import pyplot as plt

sns.set_theme(style="whitegrid")
plt.rcParams["font.sans-serif"] = ["SimHei", "Microsoft YaHei"]
plt.rcParams["axes.unicode_minus"] = False


# æ•°æ®ç±»ï¼Œè´Ÿè´£åŠ è½½æ•°æ®å¹¶æä¾›åŸºæœ¬çš„æ¦‚è§ˆåŠŸèƒ½
class Data:
    def __init__(self, filePath: str):
        self.filePath = filePath
        self.data = self.loadData()

    def loadData(self) -> pd.DataFrame:
        """åŠ è½½ CSV æ•°æ®æ–‡ä»¶"""
        self.data = pd.read_csv(self.filePath)
        return self.data

    def getShape(self) -> tuple:
        """è·å–æ•°æ®çš„å½¢çŠ¶"""
        return self.data.shape

    def getColumns(self) -> pd.Index:
        """è·å–æ•°æ®çš„åˆ—å"""
        return self.data.columns

    def getHead(self, n: int = 5) -> pd.DataFrame:
        """è·å–æ•°æ®çš„å‰å‡ è¡Œ"""
        return self.data.head(n)

    def getTail(self, n: int = 5) -> pd.DataFrame:
        """è·å–æ•°æ®çš„åå‡ è¡Œ"""
        return self.data.tail(n)

    def getInfo(self) -> None:
        """è·å–æ•°æ®çš„åŸºæœ¬ç±»å‹"""
        return self.data.info()

    def getDescribe(self) -> pd.DataFrame:
        """è·å–æ•°æ®çš„æè¿°æ€§ç»Ÿè®¡ä¿¡æ¯"""
        return self.data.describe()

    def getValueCounts(self) -> dict[str, pd.Series]:
        """æ¯ä¸€åˆ—çš„å–å€¼æ•°é‡"""
        valueCounts = {}
        for col in self.data.columns:
            valueCounts[col] = self.data[col].value_counts()
        return valueCounts

    def getAllInfo(self) -> None:
        """è·å–æ•°æ®é›†çš„å…¨éƒ¨åŸºæœ¬ä¿¡æ¯"""
        print("æ•°æ®é›†å½¢çŠ¶:")
        print(self.data.shape)

        print("æ•°æ®é›†çš„åˆ—å:\n", self.data.columns)

        print("æ•°æ®é›†çš„å‰5è¡Œ:\n", self.data.head())

        print("æ•°æ®é›†å5è¡Œ:\n", self.data.tail())

        print("æ•°æ®é›†ä¿¡æ¯:")
        print(self.data.info())

        print("æ•°æ®é›†æè¿°æ€§ç»Ÿè®¡ä¿¡æ¯:\n", self.data.describe())

        print("æ•°æ®é›†æ¯ä¸€åˆ—çš„å–å€¼æ•°é‡:\n", self.data.value_counts())

    def checkMissing(self) -> pd.Series:
        """æ£€æŸ¥ç¼ºå¤±å€¼"""
        missingValues = self.data.isnull().sum()
        if missingValues.sum() > 0:
            print("æœ‰ç¼ºå¤±å€¼! ç¼ºå¤±çš„åˆ—å’Œæ•°é‡ä¸º: ")
            print(missingValues[missingValues > 0])
        else:
            print("æ²¡æœ‰ç¼ºå¤±å€¼")
        return missingValues[missingValues > 0]

    def checkDuplicate(self) -> int:
        """æ£€æŸ¥é‡å¤å€¼"""
        duplicateCount = self.data.duplicated().sum()
        print(f"é‡å¤å€¼æ•°é‡: {duplicateCount}")
        return duplicateCount

    def checkOutlier(self) -> pd.DataFrame:
        """æ£€æŸ¥å¼‚å¸¸å€¼"""
        numericCols = self.data.select_dtypes(include=[np.number]).columns
        results = []

        for col in numericCols:
            Q1 = self.data[col].quantile(0.25)
            Q3 = self.data[col].quantile(0.75)
            IQR = Q3 - Q1
            lower = Q1 - 1.5 * IQR
            upper = Q3 + 1.5 * IQR
            iqrOutliers = (self.data[col] < lower) | (self.data[col] > upper)

            z = (self.data[col] - self.data[col].mean()) / self.data[col].std()
            zscoreOutliers = (z < -3) | (z > 3)

            results.append(
                {
                    "column": col,
                    "IQRå¼‚å¸¸å€¼": int(iqrOutliers.sum()),
                    "Z-scoreå¼‚å¸¸å€¼": int(zscoreOutliers.sum()),
                    "IQRä¸Šç•Œ": upper,
                    "IQRä¸‹ç•Œ": lower,
                }
            )

        print("æ•°å€¼åˆ—çš„å¼‚å¸¸å€¼æ£€æŸ¥ç»“æœ: ")
        report = pd.DataFrame(results)
        print(report)
        return report

    def runAllChecks(self) -> None:
        """ä¸€æ¬¡æ€§è·‘å®Œæ‰€æœ‰è´¨é‡æ£€æŸ¥"""
        self.checkMissing()
        self.checkDuplicate()
        self.checkOutlier()

    def getNonOutlier(self, col: str, method: str = "IQR") -> pd.DataFrame:
        """è·å–å‰”é™¤å¼‚å¸¸å€¼åçš„æ•°æ®"""
        if method == "IQR":
            Q1 = self.data[col].quantile(0.25)
            Q3 = self.data[col].quantile(0.75)
            IQR = Q3 - Q1
            lower = Q1 - 1.5 * IQR
            upper = Q3 + 1.5 * IQR
            return self.data[(self.data[col] >= lower) & (self.data[col] <= upper)]
        elif method == "Z-score":
            z = (self.data[col] - self.data[col].mean()) / self.data[col].std()
            return self.data[(z >= -3) & (z <= 3)]
        else:
            raise ValueError("æ¨¡å¼é”™è¯¯, è¯·é€‰æ‹© 'IQR' æˆ– 'Z-score'")

    def getSummary(self) -> pd.DataFrame:
        """è·å–æ•°æ®é›†æ‘˜è¦ä¿¡æ¯"""
        summaryDict = {}
        for col in self.data.columns:
            summaryDict[col] = {
                "æ•°æ®ç±»å‹": self.data[col].dtype,
                "éç©ºå€¼æ•°é‡": self.data[col].notnull().sum(),
                "ç¼ºå¤±å€¼æ•°é‡": self.data[col].isnull().sum(),
                "å”¯ä¸€å€¼æ•°é‡": self.data[col].nunique(),
            }
        return pd.DataFrame(summaryDict).T

    def getQualityReport(self) -> dict[str, Any]:
        """è·å–æ•°æ®è´¨é‡æŠ¥å‘Š"""
        missing = self.checkMissing()
        duplicates = self.checkDuplicate()
        outliers = self.checkOutlier()
        report = {
            "ç¼ºå¤±å€¼": missing,
            "é‡å¤å€¼æ•°é‡": duplicates,
            "å¼‚å¸¸å€¼": outliers,
        }
        return report


class Plotter:
    """å¯è§†åŒ–ç»‘å®šç±»ï¼Œè´Ÿè´£ç»‘å®š Data å¯¹è±¡å¹¶æä¾›å¯è§†åŒ–æ–¹æ³•"""

    def __init__(self, data: Data):
        # ä¿å­˜ Data å¯¹è±¡ä¸åŸå§‹ DataFrame
        self.source = data
        self.data = data.data

    def plotHist(self, col: str, dropOutliers: bool = False) -> None:
        """ç»˜åˆ¶ç›´æ–¹å›¾"""
        plotData = self.data
        if dropOutliers:
            plotData = self.source.getNonOutlier(col)
        plt.figure(figsize=(8, 6))
        ax = sns.histplot(plotData[col].dropna(), bins=30, kde=True)
        for container in ax.containers:
            ax.bar_label(container, fmt="%d", padding=2)
        plt.title(f"{col} åˆ†å¸ƒ", fontsize=14, weight="bold")
        plt.xlabel(col)
        plt.ylabel("é¢‘æ•°")
        plt.tight_layout()
        plt.show()

    def plotCount(self, col: str, data: pd.DataFrame | None = None) -> None:
        """ç»˜åˆ¶è®¡æ•°å›¾"""
        plt.figure(figsize=(8, 6))
        plotData = data if data is not None else self.data
        ax = sns.countplot(x=col, data=plotData)
        for container in ax.containers:
            ax.bar_label(container, fmt="%d", padding=3)

        # ç¾åŒ–ç»†èŠ‚
        ax.set_title(f"{col} é¢‘æ•°åˆ†å¸ƒ", fontsize=14, weight="bold")
        ax.set_xlabel(col)
        ax.set_ylabel("æ•°é‡")

        plt.tight_layout()
        plt.show()


# ç›®æ ‡å˜é‡åˆ†æ
def analyzeTarget(dataObj: Data, targetCol: str = "Survived") -> None:
    """
    åˆ†æç›®æ ‡å˜é‡çš„åˆ†å¸ƒæƒ…å†µ

    Args:
        dataObj: Data å¯¹è±¡
        targetCol: ç›®æ ‡å˜é‡åˆ—å
    """
    data = dataObj.data
    target = data[targetCol]

    # æ£€æŸ¥ç¼ºå¤±
    missing = target.isnull().sum()
    if missing > 0:
        print(f"ç›®æ ‡å˜é‡ {targetCol} æœ‰ {missing} ä¸ªç¼ºå¤±å€¼")
    else:
        print(f"ç›®æ ‡å˜é‡ {targetCol} æ²¡æœ‰ç¼ºå¤±å€¼")

    # æŸ¥çœ‹ç›®æ ‡å˜é‡ç±»åˆ«åˆ†å¸ƒ
    counts = target.value_counts().sort_index()
    percent = (counts / counts.sum()) * 100
    report = pd.DataFrame({targetCol: counts, "ç™¾åˆ†æ¯”": percent})
    print(f"ç›®æ ‡å˜é‡ {targetCol} çš„åˆ†å¸ƒ:\n{report}")

    # è®¡ç®—ä¸å¹³è¡¡ç¨‹åº¦
    if len(counts) > 1:
        imbalanceRatio = counts.max() / counts.min()
        print(f"ç±»åˆ«ä¸å¹³è¡¡ç¨‹åº¦ (æœ€å¤§ç±»åˆ«æ•°é‡ / æœ€å°ç±»åˆ«æ•°é‡): {imbalanceRatio:.2f}")

        majorityClassPercent = percent.max()
        print(f"æœ€å¤§çš„ç±»åˆ«å æ¯”: {majorityClassPercent:.2f}%")

        # è®¡ç®—ç†µ
        p = counts / counts.sum()
        entropy = -np.sum(p * np.log2(p))
        print(f"ç›®æ ‡å˜é‡çš„ç†µ: {entropy:.4f}")
    else:
        print("ç›®æ ‡å˜é‡åªæœ‰ä¸€ä¸ªç±»åˆ«, æ— æ³•è®¡ç®—ä¸å¹³è¡¡ç¨‹åº¦å’Œç†µ")

    # å¯è§†åŒ–ç›®æ ‡å˜é‡åˆ†å¸ƒ
    plt.figure(figsize=(8, 6))
    order = counts.index.tolist()
    ax = sns.countplot(x=targetCol, data=data, order=order)
    for i, patch in enumerate(ax.patches):
        ax.text(
            patch.get_x() + patch.get_width() / 2,
            patch.get_height() + 5,
            f"{counts[i]} ({percent[i]:.1f}%)",
            ha="center",
        )
    ax.set_title(f"{targetCol} åˆ†å¸ƒ", fontsize=14, weight="bold")
    ax.set_xlabel(targetCol)
    ax.set_ylabel("æ•°é‡")
    plt.tight_layout()
    plt.show()


def analyzeFeatureTarget(
    dataObj: Data,
    targetCol: str = "Survived",
    catCols: list[str] | None = None,
    numCols: list[str] | None = None,
    missing: str = "keep",
) -> None:
    """
    åˆ†æç‰¹å¾ä¸ç›®æ ‡å˜é‡çš„å…³ç³»

    Args:
        dataObj: Data å¯¹è±¡
        targetCol: ç›®æ ‡å˜é‡åˆ—å
        catCols: ç±»åˆ«ç‰¹å¾åˆ—ååˆ—è¡¨, å¦‚æœ None åˆ™è‡ªåŠ¨è¯†åˆ«
        numCols: æ•°å€¼ç‰¹å¾åˆ—ååˆ—è¡¨, å¦‚æœ None åˆ™è‡ªåŠ¨è¯†åˆ«
        missing: å¤„ç†ç¼ºå¤±å€¼çš„æ–¹å¼, "keep"(å½“æˆä¸€ç±») æˆ– "drop"(ä¸¢å¼ƒ)
    """
    # ç›®æ ‡ç¼ºå¤±ç›´æ¥åˆ é™¤
    data = dataObj.data
    data = data[data[targetCol].notnull()].copy()

    # è‡ªåŠ¨è¯†åˆ«ç±»åˆ«å’Œæ•°å€¼ç‰¹å¾
    if catCols is None:
        catCols = (
            data.select_dtypes(exclude=[np.number])
            .columns.drop(targetCol, errors="ignore")
            .tolist()
        )
    if numCols is None:
        numCols = (
            data.select_dtypes(include=[np.number])
            .columns.drop(targetCol, errors="ignore")
            .tolist()
        )

    # åˆ†æç±»åˆ«ç‰¹å¾
    for col in catCols:
        categorySeries = data[col].copy()

        # å¤„ç†ç¼ºå¤±å€¼
        if missing == "keep":
            # æŠŠç¼ºå¤±å€¼å½“æˆä¸€ä¸ªç±»åˆ« "Missing"
            categorySeries = categorySeries.fillna("Missing")
            # åˆ›å»ºä¸€ä¸ªæ–°çš„ DataFrame ç”¨äºåˆ†æå’Œå¯è§†åŒ–
            categoryFrame = data.copy()
            # æ›¿æ¢åŸæ¥çš„åˆ—ä¸ºå¤„ç†åçš„ç±»åˆ«åˆ—
            categoryFrame[col] = categorySeries
        elif missing == "drop":
            # åªåœ¨å½“å‰åˆ†æé‡Œä¸¢æ‰ç¼ºå¤±å€¼
            nonMissingMask = categorySeries.notna()
            # æ›´æ–°ç±»åˆ«åˆ—å’Œåˆ†æç”¨çš„ DataFrame
            categorySeries = categorySeries[nonMissingMask]
            # åˆ›å»ºä¸€ä¸ªæ–°çš„ DataFrame ç”¨äºåˆ†æå’Œå¯è§†åŒ–, åªåŒ…å«éç¼ºå¤±å€¼çš„è¡Œ
            categoryFrame = data.loc[nonMissingMask].copy()
            # æ›¿æ¢åŸæ¥çš„åˆ—ä¸ºå¤„ç†åçš„ç±»åˆ«åˆ—
            categoryFrame[col] = categorySeries
        else:
            raise ValueError("missing å‚æ•°å¿…é¡»æ˜¯ 'keep' æˆ– 'drop'")

        # æŸ¥çœ‹æ¯ä¸€ä¸ªåˆ—åˆ«çš„ç›®æ ‡å‡å€¼
        print(f"åˆ†æç±»åˆ«ç‰¹å¾ '{col}' ä¸ç›®æ ‡å˜é‡ '{targetCol}' çš„å…³ç³»:")
        categorySurvivalRate = (
            categoryFrame.groupby(col)[targetCol].mean().sort_values(ascending=False)
        )
        print(categorySurvivalRate)

        # äº¤å‰è¡¨
        crosstab = pd.crosstab(
            categoryFrame[col],
            categoryFrame[targetCol],
            margins=True,
            normalize="index",
        )
        print(
            f"ç±»åˆ«ç‰¹å¾ '{col}' ä¸ç›®æ ‡å˜é‡ '{targetCol}' çš„äº¤å‰è¡¨ (è¡Œç™¾åˆ†æ¯”):\n{crosstab}"
        )

        # å¯è§†åŒ–
        plt.figure(figsize=(7, 4))
        sns.barplot(x=categorySurvivalRate.index, y=categorySurvivalRate.values)
        plt.title(f"{col} å„ç±»åˆ«çš„ {targetCol} å‡å€¼", fontsize=14, weight="bold")
        plt.xlabel(col)
        plt.ylabel(f"{targetCol} å‡å€¼")
        plt.xticks(rotation=30)
        plt.tight_layout()
        plt.show()

    # åˆ†ææ•°å€¼ç‰¹å¾
    for numCol in numCols:
        # æ•°å€¼ç‰¹å¾ç¼ºå¤±å¤„ç†ï¼škeep -> ä¿ç•™ç¼ºå¤±ï¼ˆç»Ÿè®¡é‡Œè‡ªç„¶å¿½ç•¥ï¼‰
        # drop -> åªå¯¹è¯¥åˆ—ç¼ºå¤±è¡Œåšåˆ é™¤
        numericFrame = data if missing == "keep" else data[data[numCol].notna()].copy()

        # 1) ä¸åŒç›®æ ‡ç±»åˆ«ä¸‹çš„æè¿°ç»Ÿè®¡
        print(f"\n[{numCol}] ä¸åŒç›®æ ‡ç±»åˆ«çš„ç»Ÿè®¡")
        groupedStats = numericFrame.groupby(targetCol)[numCol].describe()[
            ["mean", "std", "min", "max"]
        ]
        print(groupedStats)

        # 2) ç®±çº¿å›¾ï¼šçœ‹ä¸­ä½æ•°ã€ç¦»æ•£ç¨‹åº¦ã€å¼‚å¸¸å€¼å·®å¼‚
        plt.figure(figsize=(8, 4))
        sns.boxplot(x=targetCol, y=numCol, data=numericFrame)
        plt.title(f"{numCol} æŒ‰ {targetCol} åˆ†ç»„ç®±çº¿å›¾", fontsize=14, weight="bold")
        plt.xlabel(targetCol)
        plt.ylabel(numCol)
        plt.tight_layout()
        plt.show()

        # 3) åˆ†å¸ƒå¯¹æ¯”ï¼šç›´æ–¹å›¾+KDEï¼Œçœ‹ä¸¤ç±»æ˜¯å¦æ˜æ˜¾åˆ†å¼€
        plt.figure(figsize=(8, 4))
        sns.histplot(
            data=numericFrame,
            x=numCol,
            hue=targetCol,
            kde=True,
            stat="density",
            common_norm=False,
        )
        plt.title(f"{numCol} æŒ‰ {targetCol} åˆ†ç»„åˆ†å¸ƒ", fontsize=14, weight="bold")
        plt.xlabel(numCol)
        plt.ylabel("å¯†åº¦")
        plt.tight_layout()
        plt.show()


def analyzeFeatureRelations(
    dataObj: Data,
    numCols: list[str] | None = None,
    targetCol: str | None = "Survived",
    threshold: float = 0.7,
) -> pd.DataFrame:
    """
    åˆ†æç‰¹å¾ä¹‹é—´çš„å…³ç³»ï¼ˆç›¸å…³æ€§ã€å…±çº¿æ€§ï¼‰

    Args:
        dataObj: Data å¯¹è±¡
        numCols: æ•°å€¼ç‰¹å¾åˆ—ååˆ—è¡¨, å¦‚æœ None åˆ™è‡ªåŠ¨è¯†åˆ«
        targetCol: ç›®æ ‡å˜é‡åˆ—å, è‡ªåŠ¨è¯†åˆ«æ—¶ä¼šæ’é™¤è¯¥åˆ—
        threshold: é«˜ç›¸å…³æ€§é˜ˆå€¼, é»˜è®¤ 0.7

    Returns:
        ç›¸å…³æ€§çŸ©é˜µ DataFrame
    """
    data = dataObj.data

    # è‡ªåŠ¨è¯†åˆ«æ•°å€¼ç‰¹å¾ï¼Œæ’é™¤ç›®æ ‡å˜é‡
    if numCols is None:
        numCols = data.select_dtypes(include=[np.number]).columns.tolist()
        if targetCol and targetCol in numCols:
            numCols.remove(targetCol)

    if len(numCols) < 2:
        print("âš ï¸ æ•°å€¼ç‰¹å¾å°‘äº2ä¸ªï¼Œæ— æ³•è¿›è¡Œç›¸å…³æ€§åˆ†æ")
        return pd.DataFrame()

    # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
    corrMatrix = data[numCols].corr()

    print("=" * 60)
    print("ğŸ“Š ç‰¹å¾ç›¸å…³æ€§åˆ†æ")
    print("=" * 60)
    print("\nç›¸å…³æ€§çŸ©é˜µ:")
    print(corrMatrix.round(3))

    # æ‰¾å‡ºé«˜ç›¸å…³æ€§ç‰¹å¾å¯¹
    print(f"\né«˜ç›¸å…³æ€§ç‰¹å¾å¯¹ (|r| > {threshold}):")
    highCorrPairs = []
    for i in range(len(numCols)):
        for j in range(i + 1, len(numCols)):
            corr = corrMatrix.iloc[i, j]
            if abs(corr) > threshold:
                highCorrPairs.append(
                    {
                        "ç‰¹å¾1": numCols[i],
                        "ç‰¹å¾2": numCols[j],
                        "ç›¸å…³ç³»æ•°": round(corr, 3),
                    }
                )
    if highCorrPairs:
        highCorrDf = pd.DataFrame(highCorrPairs)
        print(highCorrDf)
        print("\nâš ï¸ å­˜åœ¨é«˜åº¦ç›¸å…³çš„ç‰¹å¾ï¼Œå»ºè®®è€ƒè™‘åˆ é™¤æˆ–åˆå¹¶")
    else:
        print("âœ… æœªå‘ç°é«˜åº¦ç›¸å…³çš„ç‰¹å¾å¯¹")

    # å¯è§†åŒ–ï¼šçƒ­åŠ›å›¾
    plt.figure(figsize=(10, 8))
    sns.heatmap(
        corrMatrix,
        annot=True,
        fmt=".2f",
        cmap="RdBu_r",
        center=0,
        square=True,
        linewidths=0.5,
    )
    plt.title("ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾", fontsize=14, weight="bold")
    plt.tight_layout()
    plt.show()

    return corrMatrix


def generatePreprocessSuggestions(dataObj: Data, targetCol: str = "Survived") -> None:
    """
    ç”Ÿæˆåˆæ­¥æ•°æ®é¢„å¤„ç†å»ºè®®

    Args:
        dataObj: Data å¯¹è±¡
        targetCol: ç›®æ ‡å˜é‡åˆ—å
    """
    data = dataObj.data

    print("=" * 60)
    print("ğŸ“‹ åˆæ­¥æ•°æ®é¢„å¤„ç†å»ºè®®")
    print("=" * 60)

    # 1. ç¼ºå¤±å€¼å¤„ç†å»ºè®®
    print("\nã€1. ç¼ºå¤±å€¼å¤„ç†å»ºè®®ã€‘")
    missingCols = data.isnull().sum()
    missingCols = missingCols[missingCols > 0]
    if len(missingCols) > 0:
        for col in missingCols.index:
            missingRatio = missingCols[col] / len(data) * 100
            dtype = data[col].dtype

            # ä½¿ç”¨ str(dtype) æˆ– .name å±æ€§è¿›è¡Œæ¯”è¾ƒï¼Œç¡®ä¿å…¼å®¹ pandas dtype å¯¹è±¡
            dtypeName = str(dtype)

            if missingRatio > 50:
                print(
                    f"  - {col}: ç¼ºå¤±ç‡ {missingRatio:.1f}%ï¼Œå»ºè®®åˆ é™¤è¯¥åˆ—æˆ–ä½¿ç”¨æŒ‡ç¤ºå˜é‡"
                )
            elif dtypeName in ["object", "string", "category"] or dtypeName.startswith(
                "string"
            ):
                print(
                    f"  - {col}: ç¼ºå¤±ç‡ {missingRatio:.1f}%ï¼Œå»ºè®®ç”¨ä¼—æ•°å¡«å……æˆ–æ–°å»º 'Missing' ç±»åˆ«"
                )
            else:
                print(
                    f"  - {col}: ç¼ºå¤±ç‡ {missingRatio:.1f}%ï¼Œå»ºè®®ç”¨ä¸­ä½æ•°/å‡å€¼å¡«å……æˆ–ä½¿ç”¨æ¨¡å‹æ’è¡¥"
                )
    else:
        print("  âœ… æ— ç¼ºå¤±å€¼")

    # 2. ç±»åˆ«ç‰¹å¾ç¼–ç å»ºè®®
    print("\nã€2. ç±»åˆ«ç‰¹å¾ç¼–ç å»ºè®®ã€‘")
    catCols = data.select_dtypes(
        include=["object", "string", "category"]
    ).columns.tolist()
    if targetCol in catCols:
        catCols.remove(targetCol)

    if catCols:
        for col in catCols:
            nunique = data[col].nunique()
            if nunique == 2:
                print(f"  - {col}: äºŒåˆ†ç±»ï¼Œå»ºè®®ä½¿ç”¨ Label Encoding æˆ–äºŒå€¼åŒ–")
            elif nunique <= 10:
                print(f"  - {col}: {nunique} ä¸ªç±»åˆ«ï¼Œå»ºè®®ä½¿ç”¨ One-Hot Encoding")
            else:
                print(
                    f"  - {col}: {nunique} ä¸ªç±»åˆ«ï¼Œå»ºè®®ä½¿ç”¨ Target Encoding æˆ–é¢‘ç‡ç¼–ç "
                )
    else:
        print("  âœ… æ— éœ€ç¼–ç çš„ç±»åˆ«ç‰¹å¾")

    # 3. æ•°å€¼ç‰¹å¾å¤„ç†å»ºè®®
    print("\nã€3. æ•°å€¼ç‰¹å¾å¤„ç†å»ºè®®ã€‘")
    numCols = data.select_dtypes(include=[np.number]).columns.tolist()
    if targetCol in numCols:
        numCols.remove(targetCol)

    if numCols:
        for col in numCols:
            skewness = data[col].skew()
            if abs(skewness) > 1:
                print(f"  - {col}: ååº¦ {skewness:.2f}ï¼Œå»ºè®®è¿›è¡Œ log/sqrt å˜æ¢")

            # æ£€æŸ¥å¼‚å¸¸å€¼
            Q1 = data[col].quantile(0.25)
            Q3 = data[col].quantile(0.75)
            IQR = Q3 - Q1
            outlierCount = (
                (data[col] < Q1 - 1.5 * IQR) | (data[col] > Q3 + 1.5 * IQR)
            ).sum()
            if outlierCount > 0:
                print(
                    f"  - {col}: æœ‰ {outlierCount} ä¸ªå¼‚å¸¸å€¼ï¼Œå»ºè®®æˆªæ–­æˆ– Winsorize å¤„ç†"
                )
    else:
        print("  âœ… æ— æ•°å€¼ç‰¹å¾")

    # 4. ç‰¹å¾å·¥ç¨‹å»ºè®®
    print("\nã€4. ç‰¹å¾å·¥ç¨‹å»ºè®®ã€‘")
    print("  - è€ƒè™‘ä» Name æå–ç§°è°“ (Mr, Mrs, Miss ç­‰)")
    print("  - è€ƒè™‘åˆå¹¶ SibSp å’Œ Parch ä¸º FamilySize")
    print("  - è€ƒè™‘ä» Cabin æå–èˆ±ä½ç­‰çº§ (A, B, C ç­‰)")
    print("  - è€ƒè™‘å¯¹ Fare è¿›è¡Œåˆ†ç®±å¤„ç†")
    print("  - è€ƒè™‘å¯¹ Age è¿›è¡Œåˆ†ç®±å¤„ç†")


def main(filename: str, targetCol: str = "Survived") -> None:
    """
    æ‰§è¡Œå®Œæ•´çš„ EDA æµç¨‹

    Args:
        filename: æ•°æ®æ–‡ä»¶åï¼ˆä½äº datasets ç›®å½•ä¸‹ï¼‰
        targetCol: ç›®æ ‡å˜é‡åˆ—åï¼Œé»˜è®¤ä¸º "Survived"
    """
    filepath = os.path.join("datasets", filename)

    data = Data(filepath)

    # æ£€æŸ¥ç›®æ ‡åˆ—æ˜¯å¦å­˜åœ¨
    hasTarget = targetCol in data.data.columns

    print("æ•°æ®é›†åŸºæœ¬ä¿¡æ¯:")
    data.getAllInfo()

    print("\næ•°æ®è´¨é‡æ£€æŸ¥:")
    data.runAllChecks()

    print("\nå¯è§†åŒ–:")
    plotter = Plotter(data)

    # ç›®æ ‡å˜é‡å¯è§†åŒ–ï¼ˆä»…å½“ç›®æ ‡åˆ—å­˜åœ¨æ—¶ï¼‰
    if hasTarget:
        plotter.plotCount(targetCol)

    # å…¶ä»–ç‰¹å¾å¯è§†åŒ–
    plotter.plotCount("Pclass")
    plotter.plotCount("Sex")
    plotter.plotCount("SibSp")
    plotter.plotCount("Parch")
    plotter.plotCount("Embarked")

    # Cabin é¦–å­—æ¯å¯è§†åŒ–ï¼ˆä½¿ç”¨å‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹åŸæ•°æ®ï¼‰
    cabinFirstLetter = data.data["Cabin"].str[0].fillna("Unknown")
    plotter.plotCount("Cabin", data=pd.DataFrame({"Cabin": cabinFirstLetter}))

    # ç›´æ–¹å›¾(å¯é€‰æ‹©æ˜¯å¦å‰”é™¤å¼‚å¸¸å€¼)
    plotter.plotHist("Age", dropOutliers=True)
    plotter.plotHist("Fare", dropOutliers=True)

    # ä»¥ä¸‹åˆ†æä»…å½“ç›®æ ‡åˆ—å­˜åœ¨æ—¶æ‰§è¡Œ
    if hasTarget:
        # ç›®æ ‡å˜é‡åˆ†æ
        analyzeTarget(data, targetCol=targetCol)

        # ç‰¹å¾ä¸ç›®æ ‡å…³ç³»åˆ†æ
        analyzeFeatureTarget(
            data,
            targetCol=targetCol,
            missing="keep",
            catCols=["Pclass", "Sex", "SibSp", "Parch", "Embarked"],
            numCols=["Age", "Fare"],
        )

        # ç‰¹å¾ä¹‹é—´å…³ç³»åˆ†æ
        analyzeFeatureRelations(data, targetCol=targetCol)

        # ç”Ÿæˆé¢„å¤„ç†å»ºè®®
        generatePreprocessSuggestions(data, targetCol=targetCol)
    else:
        print(f"\nâš ï¸ ç›®æ ‡åˆ— '{targetCol}' ä¸å­˜åœ¨ï¼Œè·³è¿‡ç›®æ ‡ç›¸å…³åˆ†æ")

        # ä»…æ‰§è¡Œç‰¹å¾ä¹‹é—´å…³ç³»åˆ†æï¼ˆæ— éœ€ç›®æ ‡åˆ—ï¼‰
        analyzeFeatureRelations(data, targetCol=None)

        # ç”Ÿæˆé¢„å¤„ç†å»ºè®®ï¼ˆæ— ç›®æ ‡åˆ—ç‰ˆæœ¬ï¼‰
        generatePreprocessSuggestions(data, targetCol=targetCol)


if __name__ == "__main__":
    main("train.csv")
    # main("test.csv")
